{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SVoU7VrzGzxn"},"outputs":[],"source":["!pip install openai\n","!pip install numpy\n","!pip install tiktoken\n","!pip install Gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WysuPFYQHfCq"},"outputs":[],"source":["import openai\n","import csv\n","import json\n","import os\n","import numpy as np\n","from collections import defaultdict\n","import tiktoken\n","import gradio as gr"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["file_path = \"/content/drive/MyDrive/Colab Notebooks/hidden-api/api_key.txt\"\n","with open(file_path, 'r') as file:\n","    api_key = file.read().strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySonCJu2I1KD"},"outputs":[],"source":["#Load CSV data in\n","csv_file_path = '/content/drive/MyDrive/Colab Notebooks/Fine-Tune3.5-Turbo/helper-example.csv'\n","cleaned_data = []\n","\n","with open(csv_file_path, 'r', encoding='utf-8-sig') as file:\n","    csv_reader = csv.reader(file)\n","    for row in csv_reader:\n","        for cell in row:\n","            try:\n","                # Replace square brackets and inner double quotes that are problematic\n","                cell = cell.replace('[\"', '').replace('\"]', '').replace('\\\\\"', '\"')\n","\n","                # Load each cell as a JSON object\n","                cell_json = json.loads(cell)\n","\n","                # Now that the content is clean, append to cleaned_data list\n","                cleaned_data.append(cell_json)\n","            except json.JSONDecodeError as e:\n","                print(f\"JSON decode error for cell '{cell}': {e}\")\n","\n","jsonl_file_path = '/content/drive/MyDrive/Colab Notebooks/Fine-Tune3.5-Turbo/helper-example-json.jsonl'\n","# Write cleaned data to a JSONL file\n","with open(jsonl_file_path, 'w', encoding='utf-8') as jsonl_file:\n","    for item in cleaned_data:\n","        jsonl_file.write(json.dumps(item) + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NNdePOiKuKW"},"outputs":[],"source":["#from OpenAI website to format data;  https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n","\n","# Next, we specify the data path and open the JSONL file\n","\n","data_path = '/content/drive/MyDrive/Colab Notebooks/Fine-Tune3.5-Turbo/helper-example-json.jsonl'\n","\n","# Load dataset\n","with open(data_path) as f:\n","    dataset = [json.loads(line) for line in f]\n","\n","# We can inspect the data quickly by checking the number of examples and the first item\n","\n","# Initial dataset stats\n","print(\"Num examples:\", len(dataset))\n","print(\"First example:\")\n","for message in dataset[0][\"messages\"]:\n","    print(message)\n","\n","# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n","\n","# Format error checks\n","format_errors = defaultdict(int)\n","\n","for ex in dataset:\n","    if not isinstance(ex, dict):\n","        format_errors[\"data_type\"] += 1\n","        continue\n","\n","    messages = ex.get(\"messages\", None)\n","    if not messages:\n","        format_errors[\"missing_messages_list\"] += 1\n","        continue\n","\n","    for message in messages:\n","        if \"role\" not in message or \"content\" not in message:\n","            format_errors[\"message_missing_key\"] += 1\n","\n","        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n","            format_errors[\"message_unrecognized_key\"] += 1\n","\n","        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n","            format_errors[\"unrecognized_role\"] += 1\n","\n","        content = message.get(\"content\", None)\n","        if not content or not isinstance(content, str):\n","            format_errors[\"missing_content\"] += 1\n","\n","    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","        format_errors[\"example_missing_assistant_message\"] += 1\n","\n","if format_errors:\n","    print(\"Found errors:\")\n","    for k, v in format_errors.items():\n","        print(f\"{k}: {v}\")\n","else:\n","    print(\"No errors found\")\n","\n","# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n","\n","# Token counting functions\n","encoding = tiktoken.get_encoding(\"cl100k_base\")\n","\n","# not exact!\n","# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n","def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n","    num_tokens = 0\n","    for message in messages:\n","        num_tokens += tokens_per_message\n","        for key, value in message.items():\n","            num_tokens += len(encoding.encode(value))\n","            if key == \"name\":\n","                num_tokens += tokens_per_name\n","    num_tokens += 3\n","    return num_tokens\n","\n","def num_assistant_tokens_from_messages(messages):\n","    num_tokens = 0\n","    for message in messages:\n","        if message[\"role\"] == \"assistant\":\n","            num_tokens += len(encoding.encode(message[\"content\"]))\n","    return num_tokens\n","\n","def print_distribution(values, name):\n","    print(f\"\\n#### Distribution of {name}:\")\n","    print(f\"min / max: {min(values)}, {max(values)}\")\n","    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n","    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n","\n","# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n","\n","# Warnings and tokens counts\n","n_missing_system = 0\n","n_missing_user = 0\n","n_messages = []\n","convo_lens = []\n","assistant_message_lens = []\n","\n","for ex in dataset:\n","    messages = ex[\"messages\"]\n","    if not any(message[\"role\"] == \"system\" for message in messages):\n","        n_missing_system += 1\n","    if not any(message[\"role\"] == \"user\" for message in messages):\n","        n_missing_user += 1\n","    n_messages.append(len(messages))\n","    convo_lens.append(num_tokens_from_messages(messages))\n","    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n","\n","print(\"Num examples missing system message:\", n_missing_system)\n","print(\"Num examples missing user message:\", n_missing_user)\n","print_distribution(n_messages, \"num_messages_per_example\")\n","print_distribution(convo_lens, \"num_total_tokens_per_example\")\n","print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n","n_too_long = sum(l > 4096 for l in convo_lens)\n","print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n","\n","# Pricing and default n_epochs estimate\n","MAX_TOKENS_PER_EXAMPLE = 4096\n","\n","MIN_TARGET_EXAMPLES = 100\n","MAX_TARGET_EXAMPLES = 25000\n","TARGET_EPOCHS = 3\n","MIN_EPOCHS = 1\n","MAX_EPOCHS = 25\n","\n","n_epochs = TARGET_EPOCHS\n","n_train_examples = len(dataset)\n","if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n","    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n","elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n","    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n","\n","n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n","print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n","print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n","print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n","\n","# Calculate the estimated cost for fine-tuning\n","cost_per_100k_tokens = 0.80  # Cost for every 100,000 tokens\n","estimated_cost = ((n_epochs * n_billing_tokens_in_dataset) / 100000) * cost_per_100k_tokens\n","print(f\"Estimated cost for fine-tuning: approximately ${estimated_cost:.2f}\") #I added this for actual cost based on current pricing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GME1BGqXNGMQ"},"outputs":[],"source":["# Function to save the dataset as a JSONL file\n","def save_to_jsonl(conversations, file_path):\n","    with open(file_path, 'w') as file:\n","        for conversation in conversations:\n","            json_line = json.dumps(conversation)\n","            file.write(json_line + '\\n')\n","\n","# Specify the path where you want to save the JSONL file in your Google Drive\n","jsonl_file_path = '/content/drive/MyDrive/Colab Notebooks/Fine-Tune3.5-Turbo/helper-example-json-clean.jsonl'\n","# Save the dataset to the specified file path\n","save_to_jsonl(dataset, jsonl_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d403QpVVN3BU"},"outputs":[],"source":["#Upload data for training\n","training_file_name = '/content/drive/MyDrive/Colab Notebooks/Fine-Tune3.5-Turbo/helper-example-json-clean.jsonl'\n","\n","training_response = openai.File.create(\n","    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",")\n","training_file_id = training_response[\"id\"]\n","\n","#Gives training file id\n","print(\"Training file id:\", training_file_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlZEZYGTOY-L"},"outputs":[],"source":["#Create Fine-Tuning Job\n","suffix_name = \"chatner-bot\"\n","\n","response = openai.FineTuningJob.create(\n","    training_file=training_file_id,\n","    model=\"gpt-3.5-turbo\",\n","    suffix=suffix_name,\n",")\n","\n","job_id = response[\"id\"]\n","\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Xyzue2SPYaZ"},"outputs":[],"source":["#list events as fine-tuning progresses\n","response = openai.FineTuningJob.list_events(id=job_id, limit=50)\n","\n","events = response[\"data\"]\n","events.reverse()\n","\n","for event in events:\n","    print(event[\"message\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUgVjlQxUMhw"},"outputs":[],"source":["#retrieve fine-tune model id\n","response = openai.FineTuningJob.retrieve(job_id)\n","fine_tuned_model_id = response[\"fine_tuned_model\"]\n","\n","print(response)\n","print(\"\\nFine-tuned model id:\", fine_tuned_model_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L7IEZScVi62"},"outputs":[],"source":["#Test it out!\n","test_messages = []\n","\n","system_message = \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"\n","test_messages.append({\"role\": \"system\", \"content\": system_message})\n","user_message = \"Where should we park\"\n","test_messages.append({\"role\": \"user\", \"content\": user_message})\n","\n","print(test_messages)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJ2FtN_IVyxC"},"outputs":[],"source":["#OpenAI Chat Completions\n","response = openai.ChatCompletion.create(\n","    model=fine_tuned_model_id, #can test it against gpt-3.5-turbo to see difference\n","    messages=test_messages,\n","    temperature=0,\n","    max_tokens=500\n",")\n","print(response[\"choices\"][0][\"message\"][\"content\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjYFpQkDWsQQ"},"outputs":[],"source":["#Gradio for a better UI\n","def generate_completion(user_prompt):\n","    hidden_context = \"\"\n","    messages = [\n","        {\"role\": \"system\", \"content\": hidden_context},\n","        {\"role\": \"user\", \"content\": user_prompt}\n","    ]\n","    response = openai.ChatCompletion.create(\n","        model=fine_tuned_model_id,\n","        messages=messages,\n","        max_tokens=100,\n","        temperature=0\n","    )\n","    return response['choices'][0]['message']['content'].strip()\n","\n","iface = gr.Interface(fn=generate_completion,\n","                     inputs=gr.inputs.Textbox(lines=5, placeholder='Question about the Airbnb?'),\n","                     outputs='text',\n","                     title=\"Chatner The Airbnb Helper\",\n","                     input_labels=\"Question\",\n","                     output_labels=\"Response\")\n","\n","iface.launch(share=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM6lQoUlvASP9CU9mF3FbtT","mount_file_id":"1OS7xqlAT9V4b_1eDO3XfFuRHKX5Vr3XX","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
